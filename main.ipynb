{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR93I2L9Ul8C"
      },
      "source": [
        "## DIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cv3p8xBUwSv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as compare_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義 Hourglass 模型和輔助函數\n",
        "class Hourglass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Hourglass, self).__init__()\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "        self.d_conv_1 = nn.Conv2d(2, 8, 5, stride=2, padding=2)\n",
        "        self.d_bn_1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.d_conv_2 = nn.Conv2d(8, 16, 5, stride=2, padding=2)\n",
        "        self.d_bn_2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.d_conv_3 = nn.Conv2d(16, 32, 5, stride=2, padding=2)\n",
        "        self.d_bn_3 = nn.BatchNorm2d(32)\n",
        "        self.s_conv_3 = nn.Conv2d(32, 4, 5, stride=1, padding=2)\n",
        "\n",
        "        self.d_conv_4 = nn.Conv2d(32, 64, 5, stride=2, padding=2)\n",
        "        self.d_bn_4 = nn.BatchNorm2d(64)\n",
        "        self.s_conv_4 = nn.Conv2d(64, 4, 5, stride=1, padding=2)\n",
        "\n",
        "        self.d_conv_5 = nn.Conv2d(64, 128, 5, stride=2, padding=2)\n",
        "        self.d_bn_5 = nn.BatchNorm2d(128)\n",
        "        self.s_conv_5 = nn.Conv2d(128, 4, 5, stride=1, padding=2)\n",
        "\n",
        "        self.d_conv_6 = nn.Conv2d(128, 256, 5, stride=2, padding=2)\n",
        "        self.d_bn_6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.u_deconv_5 = nn.ConvTranspose2d(256, 124, 4, stride=2, padding=1)\n",
        "        self.u_bn_5 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.u_deconv_4 = nn.ConvTranspose2d(128, 60, 4, stride=2, padding=1)\n",
        "        self.u_bn_4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.u_deconv_3 = nn.ConvTranspose2d(64, 28, 4, stride=2, padding=1)\n",
        "        self.u_bn_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.u_deconv_2 = nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1)\n",
        "        self.u_bn_2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.u_deconv_1 = nn.ConvTranspose2d(16, 8, 4, stride=2, padding=1)\n",
        "        self.u_bn_1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.out_deconv = nn.ConvTranspose2d(8, 3, 4, stride=2, padding=1)\n",
        "        self.out_bn = nn.BatchNorm2d(3)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        down_1 = self.d_conv_1(noise)\n",
        "        down_1 = self.d_bn_1(down_1)\n",
        "        down_1 = self.leaky_relu(down_1)\n",
        "\n",
        "        down_2 = self.d_conv_2(down_1)\n",
        "        down_2 = self.d_bn_2(down_2)\n",
        "        down_2 = self.leaky_relu(down_2)\n",
        "\n",
        "        down_3 = self.d_conv_3(down_2)\n",
        "        down_3 = self.d_bn_3(down_3)\n",
        "        down_3 = self.leaky_relu(down_3)\n",
        "        skip_3 = self.s_conv_3(down_3)\n",
        "\n",
        "        down_4 = self.d_conv_4(down_3)\n",
        "        down_4 = self.d_bn_4(down_4)\n",
        "        down_4 = self.leaky_relu(down_4)\n",
        "        skip_4 = self.s_conv_4(down_4)\n",
        "\n",
        "        down_5 = self.d_conv_5(down_4)\n",
        "        down_5 = self.d_bn_5(down_5)\n",
        "        down_5 = self.leaky_relu(down_5)\n",
        "        skip_5 = self.s_conv_5(down_5)\n",
        "\n",
        "        down_6 = self.d_conv_6(down_5)\n",
        "        down_6 = self.d_bn_6(down_6)\n",
        "        down_6 = self.leaky_relu(down_6)\n",
        "\n",
        "        up_5 = self.u_deconv_5(down_6)\n",
        "        up_5 = torch.cat([up_5, skip_5], 1)\n",
        "        up_5 = self.u_bn_5(up_5)\n",
        "        up_5 = self.leaky_relu(up_5)\n",
        "\n",
        "        up_4 = self.u_deconv_4(up_5)\n",
        "        up_4 = torch.cat([up_4, skip_4], 1)\n",
        "        up_4 = self.u_bn_4(up_4)\n",
        "        up_4 = self.leaky_relu(up_4)\n",
        "\n",
        "        up_3 = self.u_deconv_3(up_4)\n",
        "        up_3 = torch.cat([up_3, skip_3], 1)\n",
        "        up_3 = self.u_bn_3(up_3)\n",
        "        up_3 = self.leaky_relu(up_3)\n",
        "\n",
        "        up_2 = self.u_deconv_2(up_3)\n",
        "        up_2 = self.u_bn_2(up_2)\n",
        "        up_2 = self.leaky_relu(up_2)\n",
        "\n",
        "        up_1 = self.u_deconv_1(up_2)\n",
        "        up_1 = self.u_bn_1(up_1)\n",
        "        up_1 = self.leaky_relu(up_1)\n",
        "\n",
        "        out = self.out_deconv(up_1)\n",
        "        out = self.out_bn(out)\n",
        "        out = nn.Sigmoid()(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pixel_thanos(img, p=0.5):\n",
        "    assert p > 0 and p < 1, 'The probability value should lie in (0, 1)'\n",
        "    mask = torch.rand(img.shape[2], img.shape[3])\n",
        "    img[:, :, mask < p] = 0\n",
        "    mask = mask > p\n",
        "    mask = mask.unsqueeze(0).repeat(1, 3, 1, 1)\n",
        "    return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_noise(image, beta_schedule, t):\n",
        "    noise = torch.randn_like(image)\n",
        "    beta_t = beta_schedule[t]\n",
        "    alpha_t = 1 - beta_t\n",
        "    noisy_image = torch.sqrt(alpha_t) * image + torch.sqrt(1 - alpha_t) * noise\n",
        "    return noisy_image, noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_model_and_optimizer(lr=1e-2, device='mps'):\n",
        "    model = Hourglass()\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    return model, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(n_iter, model, optimizer, x, mask, z, n):\n",
        "    mse = nn.MSELoss()\n",
        "    losses = []\n",
        "    ssim_scores = []\n",
        "    images = []\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y = model(z)\n",
        "        loss = mse(x, y * mask)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_np = (y * mask)[0].cpu().detach().permute(1, 2, 0).numpy()\n",
        "            x_np = (x * mask)[0].cpu().detach().permute(1, 2, 0).numpy()\n",
        "            ssim_score = compare_ssim(x_np, y_np, win_size=7, channel_axis=2, data_range=1.0)\n",
        "            ssim_scores.append(ssim_score)\n",
        "\n",
        "        if (i + 1) % 25 == 0 or i == 0:\n",
        "            with torch.no_grad():\n",
        "                out = x + y * (~mask)\n",
        "                out = out[0].cpu().detach().permute(1, 2, 0) * 255\n",
        "                out = np.array(out, np.uint8)\n",
        "                if i == 0 or (i + 1) % n == 0:\n",
        "                    images.append(out)\n",
        "        \n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Iteration: {} Loss: {:.07f} SSIM: {:.07f}'.format(i + 1, losses[-1], ssim_scores[-1]))\n",
        "    \n",
        "    return losses, images, ssim_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path):\n",
        "    image = Image.open(image_path).resize((512, 512))\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    input_tensor = to_tensor(image).unsqueeze(0)\n",
        "    if input_tensor.shape[1] == 4:\n",
        "        input_tensor = input_tensor[:, :3, :, :]\n",
        "    return input_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_noisy_images(input_tensor, beta_schedules, schedule_names, num_images=10):\n",
        "    stepsize = len(beta_schedules[0]) // num_images\n",
        "\n",
        "    noisy_images_dict = {name: [] for name in schedule_names}\n",
        "\n",
        "    fig, axs = plt.subplots(len(beta_schedules), num_images, figsize=(15, 10))\n",
        "\n",
        "    for row_idx, betas in enumerate(beta_schedules):\n",
        "        image = input_tensor.clone().to(device)\n",
        "        for col_idx in range(num_images):\n",
        "            t = col_idx * stepsize\n",
        "            noisy_image, noise = add_noise(image, betas, t)\n",
        "            noisy_image_clipped = torch.clamp(noisy_image, 0, 1)\n",
        "            axs[row_idx, col_idx].imshow(noisy_image_clipped[0].cpu().permute(1, 2, 0).numpy())\n",
        "            axs[row_idx, col_idx].axis('off')\n",
        "            if col_idx == 0:\n",
        "                axs[row_idx, col_idx].set_title(schedule_names[row_idx])\n",
        "            \n",
        "            noisy_images_dict[schedule_names[row_idx]].append(noisy_image)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return noisy_images_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_visualize(image_path):\n",
        "    # 加載並處理圖像\n",
        "    input_tensor = load_and_preprocess_image(image_path)\n",
        "\n",
        "    # 設置 beta schedules\n",
        "    T = 1000\n",
        "    lin_betas = torch.linspace(0.0001, 1.0, T)\n",
        "    cos_betas = 1.0 * (1 - torch.cos(torch.linspace(0, np.pi / 2, T)))\n",
        "    qud_betas = torch.linspace(0.0001, 1.0, T) ** 2\n",
        "    sig_betas = torch.sigmoid(torch.linspace(-6, 6, T)) * 1.0\n",
        "\n",
        "    beta_schedules = [lin_betas, cos_betas, qud_betas, sig_betas]\n",
        "    schedule_names = ['Linear', 'Cosine', 'Quadratic', 'Sigmoid']\n",
        "\n",
        "    # 生成噪聲圖像\n",
        "    noisy_images_dict = generate_noisy_images(input_tensor, beta_schedules, schedule_names)\n",
        "\n",
        "    # 初始化模型和優化器\n",
        "    model1, optimizer1 = initialize_model_and_optimizer(lr, device)\n",
        "    model2, optimizer2 = initialize_model_and_optimizer(lr, device)\n",
        "    model3, optimizer3 = initialize_model_and_optimizer(lr, device)\n",
        "    model4, optimizer4 = initialize_model_and_optimizer(lr, device)\n",
        "    model5, optimizer5 = initialize_model_and_optimizer(lr, device)\n",
        "\n",
        "    # 訓練模型 1\n",
        "    x, mask = pixel_thanos(input_tensor, 0.8)\n",
        "    z1 = torch.empty((1, 2, 512, 512)).normal_().to(device)\n",
        "    mask = mask.to(device)\n",
        "    x = x.to(device)\n",
        "    losses1, images1, ssim1 = train_model(n_iter1, model1, optimizer1, x, mask, z1, 200)\n",
        "\n",
        "    # 顯示模型 1 的結果\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n",
        "    for idx, img in enumerate(images1[:num_images]):\n",
        "        axes[idx].imshow(img.astype(np.uint8))\n",
        "        axes[idx].set_title(f'Iteration {200 * (idx + 1)} - Original')\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 訓練模型 2 並顯示結果（Linear）\n",
        "    linear_noisy_images = noisy_images_dict['Linear']\n",
        "    linear_noisy_images.reverse()\n",
        "\n",
        "    processed_images = []\n",
        "    processed_losses = []\n",
        "\n",
        "    for noisy_image in linear_noisy_images:\n",
        "        x, mask = pixel_thanos(noisy_image, 0.8)\n",
        "        mask = mask.to(device)\n",
        "        x = x.to(device)\n",
        "        losses2, images2, ssim2 = train_model(n_iter2, model2, optimizer2, x, mask, z1, 200)\n",
        "        processed_losses.extend(losses2)\n",
        "        processed_images.append(images2[-1])\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n",
        "    for idx, img in enumerate(processed_images):\n",
        "        axes[idx].imshow(img.astype(np.uint8))\n",
        "        axes[idx].set_title(f'Processed Image {idx + 1} - Linear')\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 訓練模型 3 並顯示結果（Cosine）\n",
        "    cosine_noisy_images = noisy_images_dict['Cosine']\n",
        "    cosine_noisy_images.reverse()\n",
        "\n",
        "    processed_images_cosine = []\n",
        "    processed_losses_cosine = []\n",
        "\n",
        "    for noisy_image in cosine_noisy_images:\n",
        "        x, mask = pixel_thanos(noisy_image, 0.8)\n",
        "        mask = mask.to(device)\n",
        "        x = x.to(device)\n",
        "        losses3, images3, ssim3 = train_model(n_iter2, model3, optimizer3, x, mask, z1, 200)\n",
        "        processed_losses_cosine.extend(losses3)\n",
        "        processed_images_cosine.append(images3[-1])\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n",
        "    for idx, img in enumerate(processed_images_cosine):\n",
        "        axes[idx].imshow(img.astype(np.uint8))\n",
        "        axes[idx].set_title(f'Processed Image {idx + 1} - Cosine')\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 訓練模型 4 並顯示結果（Quadratic）\n",
        "    quadratic_noisy_images = noisy_images_dict['Quadratic']\n",
        "    quadratic_noisy_images.reverse()\n",
        "\n",
        "    processed_images_quadratic = []\n",
        "    processed_losses_quadratic = []\n",
        "\n",
        "    for noisy_image in quadratic_noisy_images:\n",
        "        x, mask = pixel_thanos(noisy_image, 0.8)\n",
        "        mask = mask.to(device)\n",
        "        x = x.to(device)\n",
        "        losses4, images4, ssim4 = train_model(n_iter2, model4, optimizer4, x, mask, z1, 200)\n",
        "        processed_losses_quadratic.extend(losses4)\n",
        "        processed_images_quadratic.append(images4[-1])\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n",
        "    for idx, img in enumerate(processed_images_quadratic):\n",
        "        axes[idx].imshow(img.astype(np.uint8))\n",
        "        axes[idx].set_title(f'Processed Image {idx + 1} - Quadratic')\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 訓練模型 5 並顯示結果（Sigmoid）\n",
        "    sigmoid_noisy_images = noisy_images_dict['Sigmoid']\n",
        "    sigmoid_noisy_images.reverse()\n",
        "\n",
        "    processed_images_sigmoid = []\n",
        "    processed_losses_sigmoid = []\n",
        "\n",
        "    for noisy_image in sigmoid_noisy_images:\n",
        "        x, mask = pixel_thanos(noisy_image, 0.8)\n",
        "        mask = mask.to(device)\n",
        "        x = x.to(device)\n",
        "        losses5, images5, ssim5 = train_model(n_iter2, model5, optimizer5, x, mask, z1, 200)\n",
        "        processed_losses_sigmoid.extend(losses5)\n",
        "        processed_images_sigmoid.append(images5[-1])\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n",
        "    for idx, img in enumerate(processed_images_sigmoid):\n",
        "        axes[idx].imshow(img.astype(np.uint8))\n",
        "        axes[idx].set_title(f'Processed Image {idx + 1} - Sigmoid')\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 繪製損失曲線\n",
        "    # fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    # axes[0].plot(losses1, color='skyblue')\n",
        "    # axes[0].set_title('Losses for Model 1')\n",
        "    # axes[0].set_xlabel('Iteration')\n",
        "    # axes[0].set_ylabel('Loss')\n",
        "\n",
        "    # axes[1].plot(processed_losses, color='pink')\n",
        "    # axes[1].set_title('Losses for Model 2')\n",
        "    # axes[1].set_xlabel('Iteration')\n",
        "    # axes[1].set_ylabel('Loss')\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(losses1, label='Model 1', color='skyblue')\n",
        "    ax.plot(processed_losses, label='Model 2 (Linear)', color='pink')\n",
        "    ax.plot(processed_losses_cosine, label='Model 3 (Cosine)', color='orange')\n",
        "    ax.plot(processed_losses_quadratic, label='Model 4 (Quadratic)', color='green')\n",
        "    ax.plot(processed_losses_sigmoid, label='Model 5 (Sigmoid)', color='red')\n",
        "    ax.set_title('Losses for All Models')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 設置參數\n",
        "lr = 1e-2\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "n_iter1 = 2000\n",
        "n_iter2 = 200\n",
        "num_images = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = 'loopy.jpeg' \n",
        "train_and_visualize(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses1, images1, ssim1 = train_model(n_iter1, model1, optimizer1, x, mask, z1, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = 'cat.jpeg' \n",
        "train_and_visualize(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = 'a.jpeg' \n",
        "train_and_visualize(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
